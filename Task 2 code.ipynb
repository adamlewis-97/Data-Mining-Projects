{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22dd647-6c3d-4ff5-9d7d-4d094d6741a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Set the base directory\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Define the Data directory path\n",
    "data_dir = os.path.join(base_dir, \"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d9350-077f-47b2-aa75-ce9c693a1f2e",
   "metadata": {},
   "source": [
    "# PETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c658332-77bd-4f00-ab6e-9fc0697d6ab7",
   "metadata": {},
   "source": [
    "# Import and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a6afa-eb2d-44e5-815c-99dcf3152585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_annotations(annotation_file, image_dir):\n",
    "    \"\"\"\n",
    "    Load annotations and create a DataFrame with image paths and labels.\n",
    "    \"\"\"\n",
    "    # Load annotations file\n",
    "    annotations = pd.read_csv(\n",
    "        annotation_file, sep=\" \", skiprows=6, header=None,\n",
    "        names=[\"filename\", \"class_id\", \"species\", \"breed\"]\n",
    "    )\n",
    "    # Add the full image path to each row\n",
    "    annotations[\"image_path\"] = annotations[\"filename\"].apply(\n",
    "        lambda x: os.path.join(image_dir, x + \".jpg\")\n",
    "    )\n",
    "    return annotations\n",
    "\n",
    "# Path to dataset\n",
    "dataset_path = os.path.join(data_dir, \"The Oxford-IIIT Pet Dataset\")\n",
    "image_dir = os.path.join(dataset_path, \"images\")\n",
    "annotation_file = os.path.join(dataset_path, \"annotations\", \"list.txt\")\n",
    "\n",
    "# Load the dataset\n",
    "annotations = load_annotations(annotation_file, image_dir)\n",
    "\n",
    "# Display the first few rows\n",
    "print(annotations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e439df0-52b4-4bce-adc4-aeab21112712",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a381859-fa7b-4722-8eb7-ff93fb939f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path, transform):\n",
    "    \"\"\"\n",
    "    Preprocess a single image by applying the given transformations.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Convert to RGB\n",
    "    img_tensor = transform(img)  # Apply the transformations\n",
    "    return img_tensor\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(           # Normalise using ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2c1dc-7355-46b9-94df-33e986ad742b",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd013f6d-dca7-489c-b50f-844f76dfb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(image_paths, model, transform, device):\n",
    "    # Extract feature vectors for all images using the pre-trained model\n",
    "    features = []\n",
    "    for path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
    "        img_tensor = preprocess_image(path, transform).unsqueeze(0).to(device)  # Move tensor to device\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            feature = model(img_tensor).flatten().detach().cpu().numpy()  # Move to CPU and convert to NumPy\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "# Load ResNet18 model and remove the classification layer\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") \n",
    "model = resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the final classification layer\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Extract features for all images\n",
    "image_paths = annotations[\"image_path\"].tolist()\n",
    "features = extract_features(image_paths, model, transform, device)\n",
    "\n",
    "# Save the features\n",
    "import numpy as np\n",
    "np.save(os.path.join(data_dir, \"pet_features.npy\"), features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02457743-19ad-4063-8428-8f6e2c81e960",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86caeab-58d2-4b80-b4b9-ef0a2b470549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved features\n",
    "features = np.load(os.path.join(data_dir, \"pet_features.npy\"))\n",
    "\n",
    "# Reduce dimensions using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "reduced_features = tsne.fit_transform(features)\n",
    "\n",
    "# Save reduced features for future use\n",
    "np.save(os.path.join(data_dir, \"reduced_features.npy\"), reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a5a41-1360-4f59-b038-259503ea4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the clusters\n",
    "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=annotations[\"class_id\"], s=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"t-SNE Visualisation of Pet Features\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd64d1c-217c-41c9-be00-29378d1a0d52",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e97aa-6d5b-4142-ad91-ee71443972bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Perform k-Means clustering\n",
    "num_clusters = 37  # Number of breeds in the dataset\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a43ab-4618-47cf-9153-fe56e8aed89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the clusters\n",
    "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=cluster_labels, s=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"k-Means Clustering of Pet Features (t-SNE Reduced)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0707f-784b-46e9-ae99-04107a717d6c",
   "metadata": {},
   "source": [
    "## Davies-Bouldin Index (DBI) and Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bf9d3-1751-47bf-be6c-96824870693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "\n",
    "# Calculate DBI\n",
    "dbi = davies_bouldin_score(reduced_features, cluster_labels)\n",
    "print(dbi)\n",
    "\n",
    "# Calculate silhouette score\n",
    "silhouette_avg = silhouette_score(reduced_features, cluster_labels)\n",
    "print(silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c87f6-8d03-4486-a109-7af32ee2d160",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3c4f7-b5e8-45c0-8d32-c39f26b77c9e",
   "metadata": {},
   "source": [
    "## Simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81921fa8-0025-4836-8fbf-19f44eed68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load extracted features and labels\n",
    "features = np.load(os.path.join(data_dir, \"pet_features.npy\"))\n",
    "labels = annotations[\"class_id\"].values\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79260822-f7c5-4acf-aa13-2433ae1c5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix)\n",
    "plt.title(\"Simple Linear Regression Confusion Matrix for the Pets dataset\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74091a48-0dc5-4e2d-84fc-1a8ab4d72238",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4ba03-acb1-4cc9-8b4a-b4e44481f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluate SVM performance\n",
    "print(classification_report(y_test, y_pred_svm, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0f46a-86e5-4c37-898f-8c37df14454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for SVM\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(conf_matrix_svm)\n",
    "plt.title(\"SVM Confusion Matrix for the Pets Dataset\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965549f-54d3-4f39-acc2-66cff175c1ca",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b55444-3fff-49d1-9c87-dc21ebe3937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train a k-NN classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)  # Using 5 neighbours\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "# Evaluate k-NN performance\n",
    "print(classification_report(y_test, y_pred_knn, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bb75d-e43e-4c31-b579-06ae2e80d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for k-NN\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(conf_matrix_knn)\n",
    "plt.title(\"k-NN Confusion Matrix for the Pets dataset\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ed693-49b4-4803-a217-cf229ed71579",
   "metadata": {},
   "source": [
    "# Food-101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13143227-2c23-4210-b54b-5dae23345745",
   "metadata": {},
   "source": [
    "## importing the Food-101 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc70002-bdfb-428e-850c-e8b52654cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_food101_data(meta_folder, image_folder):\n",
    "    \"\"\"\n",
    "    Load Food-101 dataset annotations and return a DataFrame with image paths and labels.\n",
    "    \"\"\"\n",
    "    # Load train and test file paths\n",
    "    train_file = os.path.join(meta_folder, \"train.txt\")\n",
    "    test_file = os.path.join(meta_folder, \"test.txt\")\n",
    "\n",
    "    # Read train and test files into dataframes\n",
    "    train_df = pd.read_csv(train_file, header=None, names=[\"image_path\"])\n",
    "    test_df = pd.read_csv(test_file, header=None, names=[\"image_path\"])\n",
    "\n",
    "    # Extract labels from file paths\n",
    "    train_df[\"label\"] = train_df[\"image_path\"].apply(lambda x: x.split(\"/\")[0])\n",
    "    test_df[\"label\"] = test_df[\"image_path\"].apply(lambda x: x.split(\"/\")[0])\n",
    "\n",
    "    # Add full image paths\n",
    "    train_df[\"image_path\"] = train_df[\"image_path\"].apply(lambda x: os.path.join(image_folder, x + \".jpg\"))\n",
    "    test_df[\"image_path\"] = test_df[\"image_path\"].apply(lambda x: os.path.join(image_folder, x + \".jpg\"))\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Define paths\n",
    "dataset_path = os.path.join(data_dir, \"Food 101 Dataset\", \"food-101\")\n",
    "meta_folder = os.path.join(dataset_path, \"meta\")\n",
    "image_folder = os.path.join(dataset_path, \"images\")\n",
    "\n",
    "# Load the dataset\n",
    "train_df, test_df = load_food101_data(meta_folder, image_folder)\n",
    "\n",
    "# Display sample rows\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6c52b-e4d2-463c-b331-de08ec1972c1",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db35b0-ceab-4c87-8da0-1edab5d24807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path, transform):\n",
    "    \"\"\"\n",
    "    Preprocess a single image by applying the specified transformations.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img)  \n",
    "    return img_tensor\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(           # Normalise using ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fed1e2-a000-4a5b-9411-74c08dfb1ddf",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313c88a-e912-4180-92a4-de7c478be25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm \n",
    "\n",
    "def extract_features(image_paths, model, transform, device):\n",
    "    # Extract feature vectors for all images using the pre-trained model\n",
    "    features = []\n",
    "    for path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
    "        img_tensor = preprocess_image(path, transform).unsqueeze(0).to(device)  # Move tensor to device\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            feature = model(img_tensor).flatten().detach().cpu().numpy()  # Move to CPU and convert to NumPy\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "# Load ResNet18 pre-trained model and remove the classification layer\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") \n",
    "model = resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the final classification layer\n",
    "model = model.to(device) \n",
    "model.eval()\n",
    "\n",
    "# Extract features for training images\n",
    "train_image_paths = train_df[\"image_path\"].tolist()\n",
    "train_features = extract_features(train_image_paths, model, transform, device)\n",
    "\n",
    "# Save extracted features\n",
    "np.save(os.path.join(data_dir, \"food_train_features.npy\"), train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fda882-94af-430a-ab14-c1b3eb546253",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a876d9-94a6-42c3-9b72-e587daca3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the extracted features\n",
    "features = np.load(os.path.join(data_dir, \"food_train_features.npy\"))\n",
    "\n",
    "# Apply PCA to reduce to 50 dimensions\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "pca_features = pca.fit_transform(features)\n",
    "np.save(os.path.join(data_dir, \"food_pca_features.npy\"), pca_features) # Save PCA features\n",
    "\n",
    "# Apply t-SNE to reduce to 2 dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "tsne_features = tsne.fit_transform(pca_features)\n",
    "\n",
    "# Save reduced features for future use\n",
    "np.save(os.path.join(data_dir, \"food_tsne_features.npy\"), tsne_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd742a7b-55f1-4044-ae92-1f177df47a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the t-SNE results\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=train_df[\"label\"].factorize()[0], s=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"t-SNE Visualisation of Food-101 Features\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd32a5e-7990-4fd2-a4ca-31ef106f071f",
   "metadata": {},
   "source": [
    "#  k-Means clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40340410-d4a3-41ff-b2cf-940ca99c19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, adjusted_rand_score\n",
    "\n",
    "pca_features = np.load(os.path.join(data_dir, \"food_pca_features.npy\"))\n",
    "\n",
    "# Apply k-Means Clustering\n",
    "n_clusters = 101  # One cluster per food\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(pca_features)\n",
    "\n",
    "# Evaluate clustering quality\n",
    "silhouette_avg = silhouette_score(pca_features, cluster_labels)\n",
    "dbi = davies_bouldin_score(pca_features, cluster_labels)\n",
    "\n",
    "print(silhouette_avg)\n",
    "print(dbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285e51c-cf3c-4904-a85e-d675fcc94542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise clustering results\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=cluster_labels, s=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"k-Means Clustering of Food-101 Features (t-SNE Reduced)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e6d73-7eeb-4599-82b4-316519be93d0",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ee845-3064-4718-b3f8-a55e0a2dd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "def apply_hierarchical_clustering(features, n_clusters):\n",
    "\n",
    "# Perform Agglomerative Hierarchical Clustering\n",
    "    \n",
    "    # Fit Agglomerative Clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "    cluster_labels = clustering.fit_predict(features)\n",
    "\n",
    "    # Evaluate clustering performance\n",
    "    silhouette_avg = silhouette_score(features, cluster_labels)\n",
    "    dbi = davies_bouldin_score(features, cluster_labels)\n",
    "\n",
    "    print(silhouette_avg)\n",
    "    print(dbi)\n",
    "\n",
    "    return cluster_labels\n",
    "\n",
    "# Visualise the Dendrogram\n",
    "def plot_dendrogram(features, sample_size=500):\n",
    "    \n",
    "# Plotting a dendrogram using a subset of features.\n",
    "    \n",
    "    subset = features[:sample_size]  # Use the first 500 samples\n",
    "    linkage_matrix = sch.linkage(subset, method='ward')\n",
    "\n",
    "    sch.dendrogram(linkage_matrix)\n",
    "    plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.show()\n",
    "\n",
    "# Run Hierarchical Clustering\n",
    "n_clusters = 101  # Number of food classes\n",
    "plot_dendrogram(pca_features)  # Visualise dendrogram\n",
    "hierarchical_labels = apply_hierarchical_clustering(pca_features, n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c313445-38d2-4b31-a64b-50efd4be493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise Clustering\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=hierarchical_labels, s=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"Hierarchical Clustering of Food-101 Features (t-SNE Reduced)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9386fef-9db8-4556-b5bc-a7fade238b31",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b990db7-c84f-4c3c-a496-8f7f07becc7b",
   "metadata": {},
   "source": [
    "eps = 3 and min_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771568c8-88f1-48f2-96f8-00e1756717d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dbscan_clustering(reduced_features, eps=3.0, min_samples=10):\n",
    "\n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "    cluster_labels = dbscan.fit_predict(reduced_features)\n",
    "\n",
    "    # Evaluate clustering performance ignoring noise points\n",
    "    valid_indices = cluster_labels != -1\n",
    "    valid_labels = cluster_labels[valid_indices]\n",
    "    valid_features = reduced_features[valid_indices]\n",
    "\n",
    "    if len(np.unique(valid_labels)) > 1:  # Ensure valid clusters exist\n",
    "        silhouette_avg = silhouette_score(valid_features, valid_labels)\n",
    "        dbi = davies_bouldin_score(valid_features, valid_labels)\n",
    "    else:\n",
    "        silhouette_avg = None\n",
    "        dbi = None\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print({silhouette_avg} if silhouette_avg else \"Not enough clusters for Silhouette Score.\")\n",
    "    print({dbi} if dbi else \"Not enough clusters for DBI.\")\n",
    "\n",
    "    return cluster_labels\n",
    "\n",
    "# DBSCAN Parameters\n",
    "eps = 3.0  # Distance threshold\n",
    "min_samples = 10  # Minimum samples per cluster\n",
    "\n",
    "# Run DBSCAN\n",
    "dbscan_labels = dbscan_clustering(pca_features, eps=eps, min_samples=min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc46d01-8684-4f94-89da-5f0f6686a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=dbscan_labels, s=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"DBSCAN Clustering of Food-101 Features (t-SNE Reduced)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2093f4-6e91-4d1d-8cef-c5374284f143",
   "metadata": {},
   "source": [
    "Increased eps:\n",
    "Adjusted from 3.0 to 5.0 to consider a larger radius for neighbouring points.\n",
    "Reduced min_samples:\n",
    "Lowered from 10 to 5 to allow smaller clusters to form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f00c38-7d71-459d-8522-f37f8286471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dbscan_clustering(reduced_features, eps=5.0, min_samples=5):\n",
    "\n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "    cluster_labels = dbscan.fit_predict(reduced_features)\n",
    "\n",
    "    # Evaluate clustering performance ignoring noise points\n",
    "    valid_indices = cluster_labels != -1\n",
    "    valid_labels = cluster_labels[valid_indices]\n",
    "    valid_features = reduced_features[valid_indices]\n",
    "\n",
    "    if len(np.unique(valid_labels)) > 1:  # Ensure valid clusters exist\n",
    "        silhouette_avg = silhouette_score(valid_features, valid_labels)\n",
    "        dbi = davies_bouldin_score(valid_features, valid_labels)\n",
    "    else:\n",
    "        silhouette_avg = None\n",
    "        dbi = None\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print({silhouette_avg} if silhouette_avg else \"Not enough clusters for Silhouette Score.\")\n",
    "    print({dbi} if dbi else \"Not enough clusters for DBI.\")\n",
    "\n",
    "    return cluster_labels\n",
    "\n",
    "# Adjusted DBSCAN Parameters\n",
    "eps = 5.0  # Larger distance\n",
    "min_samples = 5  # Lower minimum samples per cluster\n",
    "\n",
    "# Run DBSCAN\n",
    "dbscan_labels = dbscan_clustering(pca_features, eps=eps, min_samples=min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fba6f-ddd9-4bb4-a44a-08aeebec8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=dbscan_labels, s=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"DBSCAN Clustering of Food-101 Features (t-SNE Reduced)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254aeca-835f-4699-bea7-39e670323280",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30f09a-2b34-4321-b916-d83d87cac511",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1914c058-04e2-4dc2-9ca9-d60536a79340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for testing images\n",
    "test_image_paths = test_df[\"image_path\"].tolist()\n",
    "\n",
    "# Use the GPU if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "test_features = extract_features(test_image_paths, model, transform, device)\n",
    "\n",
    "# Save the test features for reuse\n",
    "np.save(os.path.join(data_dir, \"food_test_features.npy\"), test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4e488-99dc-4aa2-aa5c-9f3d01765e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the original features\n",
    "train_features = np.load(os.path.join(data_dir, \"food_train_features.npy\"))\n",
    "test_features = np.load(os.path.join(data_dir, \"food_test_features.npy\"))\n",
    "\n",
    "# Ensure labels are correctly loaded\n",
    "train_labels = train_df[\"label\"].factorize()[0]\n",
    "test_labels = test_df[\"label\"].factorize()[0]\n",
    "\n",
    "# Train SVM\n",
    "svm = SVC(kernel=\"linear\", C=1, random_state=42)\n",
    "svm.fit(train_features, train_labels)\n",
    "\n",
    "# Test SVM\n",
    "predicted_labels = svm.predict(test_features)\n",
    "\n",
    "# Generate Classification Report\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da10b32-0b08-4ed7-a0cd-d96e9e12379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Confusion Matrix\n",
    "plt.figure(figsize=(16, 12))\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "sns.heatmap(conf_matrix, xticklabels=np.unique(test_df[\"label\"]),\n",
    "            yticklabels=np.unique(test_df[\"label\"]))\n",
    "plt.title(\"SVM Confusion Matrix for Food-101\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8888dd3-b93e-4269-8bea-fe2d78970686",
   "metadata": {},
   "source": [
    "##  k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25968bda-286e-4414-968a-089bd7c9095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the features\n",
    "train_features = np.load(os.path.join(data_dir, \"food_train_features.npy\"))\n",
    "test_features = np.load(os.path.join(data_dir, \"food_test_features.npy\"))\n",
    "\n",
    "# Load the labels\n",
    "train_labels = train_df[\"label\"].factorize()[0]\n",
    "test_labels = test_df[\"label\"].factorize()[0]\n",
    "\n",
    "# Train k-NN\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric=\"euclidean\")\n",
    "knn.fit(train_features, train_labels)\n",
    "\n",
    "# Test k-NN\n",
    "predicted_labels = knn.predict(test_features)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(test_labels, predicted_labels))\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c497d-6076-4f84-9b32-eedbec36e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the confusion matrix\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(conf_matrix,\n",
    "            xticklabels=test_df[\"label\"].unique(),\n",
    "            yticklabels=test_df[\"label\"].unique())\n",
    "plt.title(\"k-NN Confusion Matrix for Food-101\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2fcd01-ebc5-4753-abdf-c1a48009d578",
   "metadata": {},
   "source": [
    "## Fine tuning SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a63d19-fa36-479d-9693-c75ec512e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the features and labels\n",
    "train_features = np.load(os.path.join(data_dir, \"food_train_features.npy\"))\n",
    "test_features = np.load(os.path.join(data_dir, \"food_test_features.npy\"))\n",
    "train_labels = train_df[\"label\"].factorize()[0]\n",
    "test_labels = test_df[\"label\"].factorize()[0]\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],  # Regularisation parameter\n",
    "    \"kernel\": [\"linear\", \"rbf\"],  # Kernels to try\n",
    "    \"gamma\": [\"scale\", \"auto\"],  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=3, scoring=\"accuracy\", verbose=2)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_svm = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate the fine-tuned SVM\n",
    "predicted_labels = best_svm.predict(test_features)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(test_labels, predicted_labels, target_names=test_df[\"label\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2465dc-f197-4158-866b-ae7e210f243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(16, 12))\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "sns.heatmap(conf_matrix, xticklabels=test_df[\"label\"].unique(), yticklabels=test_df[\"label\"].unique())\n",
    "plt.title(\"Improved SVM Confusion Matrix for Food-101\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281acb09-f1de-4117-93bf-ce5517d73b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svm, os.path.join(data_dir, \"food101_svm_model.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
