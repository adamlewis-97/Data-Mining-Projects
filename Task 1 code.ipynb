{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4a0fb-0add-4ecf-a319-119e99d0a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the base directory\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Define the Data directory path\n",
    "data_dir = os.path.join(base_dir, \"Data\")\n",
    "\n",
    "# Define the Climate Data directory path\n",
    "climate_data_dir = os.path.join(data_dir, \"Climate Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6f4e3-0e63-4395-af39-217d5f42f9d6",
   "metadata": {},
   "source": [
    "# Data Loading and Initial Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1d556-8909-4c76-a761-530913cc1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect data\n",
    "import pandas as pd\n",
    "climate_data = pd.read_csv(os.path.join(climate_data_dir, \"ClimateDataBasel.csv\"), header=None)\n",
    "\n",
    "# Add column names\n",
    "climate_data.columns = [\n",
    "    'Temp_Min', 'Temp_Max', 'Temp_Mean',\n",
    "    'Humidity_Min', 'Humidity_Max', 'Humidity_Mean',\n",
    "    'Pressure_Min', 'Pressure_Max', 'Pressure_Mean',\n",
    "    'Precipitation', 'Snowfall', 'Sunshine',\n",
    "    'WindGust_Min', 'WindGust_Max', 'WindGust_Mean',\n",
    "    'WindSpeed_Min', 'WindSpeed_Max', 'WindSpeed_Mean'\n",
    "]\n",
    "\n",
    "print(climate_data.head())\n",
    "print(climate_data.info())\n",
    "print(climate_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230b5ca-a517-459d-b5bc-fa89dbc51233",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf3d40-05f3-4a97-a1ef-2e7350117932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = climate_data.corr()\n",
    "\n",
    "# Plot\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", annot_kws={\"size\": 6})\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa489535-5463-436d-99e3-45c7f416e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic statistics for Snowfall\n",
    "print(climate_data[\"Snowfall\"].describe())\n",
    "\n",
    "# Check unique values and their counts\n",
    "print(climate_data[\"Snowfall\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21395856-11e4-4dce-af0e-9faf11eafa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant features\n",
    "climate_data = climate_data[['Temp_Mean', 'Humidity_Mean', 'Pressure_Mean', 'Precipitation', 'WindSpeed_Mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68907a85-456e-45b4-85cc-1d57a89439e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Detect Outliers using Z-Score\n",
    "mean = climate_data.mean()\n",
    "std = climate_data.std()\n",
    "z_scores = (climate_data - mean) / std\n",
    "outliers = np.abs(z_scores) > 3\n",
    "\n",
    "# Remove rows with outliers\n",
    "cleaned_data = climate_data[~outliers.any(axis=1)]\n",
    "\n",
    "print(f\"Original rows: {len(climate_data)}, Cleaned rows: {len(cleaned_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeeb335-730e-4630-ad64-d2edfa7435a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardisation\n",
    "def standard(data):\n",
    "    \"\"\"Standardise the data to have mean = 0 and std = 1\"\"\"\n",
    "    standardData = data.copy()\n",
    "    rows, cols = data.shape\n",
    "    for j in range(cols):\n",
    "        sigma = np.std(data[:, j])  # Standard deviation\n",
    "        mu = np.mean(data[:, j])   # Mean\n",
    "        for i in range(rows):\n",
    "            standardData[i, j] = (data[i, j] - mu) / sigma\n",
    "    return standardData\n",
    "\n",
    "# Apply standardisation\n",
    "standardised_data = standard(cleaned_data.values)\n",
    "\n",
    "print(standardised_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d4278-2807-43b8-b6ea-f17a990df74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot for 'Temp_Mean'\n",
    "plt.hist(cleaned_data['Temp_Mean'], bins=25)\n",
    "plt.title(\"Original Temp_Mean Distribution\")\n",
    "plt.xlabel(\"Temp_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(standardised_data[:, 0], bins=25)\n",
    "plt.title(\"Standardised Temp_Mean Distribution\")\n",
    "plt.xlabel(\"Temp_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'Humidity_Mean'\n",
    "plt.hist(cleaned_data['Humidity_Mean'], bins=25)\n",
    "plt.title(\"Original Humidity_Mean Distribution\")\n",
    "plt.xlabel(\"Humidity_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(standardised_data[:, 1], bins=25)\n",
    "plt.title(\"Standardised Humidity_Mean Distribution\")\n",
    "plt.xlabel(\"Humidity_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'Pressure_Mean'\n",
    "plt.hist(cleaned_data['Pressure_Mean'], bins=25)\n",
    "plt.title(\"Original Pressure_Mean Distribution\")\n",
    "plt.xlabel(\"Pressure_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(standardised_data[:, 2], bins=25)\n",
    "plt.title(\"Standardised Pressure_Mean Distribution\")\n",
    "plt.xlabel(\"Pressure_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'Precipitation'\n",
    "plt.hist(cleaned_data['Precipitation'], bins=25)\n",
    "plt.title(\"Original Precipitation Distribution\")\n",
    "plt.xlabel(\"Precipitation\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(standardised_data[:, 3], bins=25)\n",
    "plt.title(\"Standardised Precipitation Distribution\")\n",
    "plt.xlabel(\"Precipitation\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'WindSpeed_Mean'\n",
    "plt.hist(cleaned_data['WindSpeed_Mean'], bins=25)\n",
    "plt.title(\"Original WindSpeed_Mean Distribution\")\n",
    "plt.xlabel(\"WindSpeed_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(standardised_data[:, 4], bins=25)\n",
    "plt.title(\"Standardised WindSpeed_Mean Distribution\")\n",
    "plt.xlabel(\"WindSpeed_Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1577d51b-e4d7-4975-ae51-7ae6c02dd2c4",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782727e6-ad88-4628-804b-7dedcd4090a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition \n",
    "\n",
    "# Feature extraction - PCA\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(standardised_data)\n",
    "pca_data = pd.DataFrame(\n",
    "    pca.transform(standardised_data),\n",
    "    columns=[\"PCA1\", \"PCA2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8230f9-2a8a-42e5-9c92-33606ff8a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for PCA transformed data\n",
    "plt.scatter(pca_data[\"PCA1\"], pca_data[\"PCA2\"], alpha=0.5)\n",
    "plt.title(\"PCA-transformed Data\")\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a480cd3-2c2e-4cdd-b08d-d8cb178fd3ae",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e22eb-b721-4517-8d73-2ef7ae97fb58",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95d4a7-a51d-4d90-9ea1-e2f75141c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Elbow method for determining the optimal number of clusters\n",
    "inertia_values = []  # Store inertia for each number of clusters\n",
    "cluster_range = range(2, 10)  # Testing for k values from 2 to 9\n",
    "\n",
    "for num_clusters in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)  # Initialize KMeans\n",
    "    kmeans.fit(pca_data)  # Fit the model to PCA-transformed data\n",
    "    inertia_values.append(kmeans.inertia_)  # Append the inertia (sum of squared distances)\n",
    "\n",
    "# Plot the elbow method results\n",
    "plt.plot(cluster_range, inertia_values, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e06620-9eac-4a5d-a924-f4580aba7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal k\n",
    "optimal_k = 3 \n",
    "\n",
    "# Apply k-means with optimal k\n",
    "optimal_kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "optimal_clusters = optimal_kmeans.fit_predict(pca_data)\n",
    "\n",
    "# Visualise k-means clusters\n",
    "plt.scatter(pca_data[\"PCA1\"], pca_data[\"PCA2\"], c=optimal_clusters, alpha=0.5)\n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62abe9bb-1fa0-45e1-82d0-d65897842d93",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17250c2-079e-4d12-965a-7cd92df6fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Apply DBSCAN\n",
    "# eps is the maximum distance between two samples for them to be in the same cluster\n",
    "# min_samples is minimum number of points required to form a dense region\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "dbscan_clusters = dbscan.fit_predict(pca_data)\n",
    "\n",
    "# Visualise DBSCAN Clusters\n",
    "plt.scatter(pca_data[\"PCA1\"], pca_data[\"PCA2\"], c=dbscan_clusters, alpha=0.5)\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fcc916-d1d2-4884-82e9-791f21bbad4f",
   "metadata": {},
   "source": [
    "## Evaluate clusterings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf3172-aaca-4e71-9096-329b0ba035fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Silhouette score for K-means\n",
    "silhouette_kmeans = silhouette_score(pca_data, optimal_clusters)\n",
    "print(silhouette_kmeans)\n",
    "\n",
    "# Silhouette score for DBSCAN \n",
    "silhouette_dbscan = silhouette_score(pca_data, dbscan_clusters)\n",
    "print(silhouette_dbscan)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
